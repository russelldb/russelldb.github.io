# Version Vectors - When History Repeats

[Last time](http://basho.com/posts/technical/vector-clocks-revisited-part-2-dotted-version-vectors/)
I wrote about how Dotted Version Vectors fix Sibling
Explosion. Sibling Explosion was a relatively common bug, often seen in
the wild. This post is about a subtle bug that manifests in a number
of different ways that all have the same outcome: silent data
loss. Don't panic, we believe this to be a very uncommon edge case
that can be mitigated against with a simple configuration change in Riak
versions less than 2.1, and that is fixed in Riak 2.1 and above.

Originally I planned on this being the final post in a trilogy. After
some work the post is still too long, so I've split it into two: *The
Problem* and *The Solution*. This post describes *The Problem*.

Over the weekend I read this paper on Distributed Computing Bugs:
[TaxDC: A Taxonomy of Non-Deterministic Concurrency Bugs in Datacenter Distributed Systems](http://ucare.cs.uchicago.edu/pdf/asplos16-TaxDC.pdf)
which includes the following passage:

> Real-world DC [Distributed Concurrency] bugs are hard to find
> because many of them linger in complex concurrent executions of
> multiple protocols. Complete real-world systems contain many
> background and operational protocols beyond user-facing foreground
> protocols. Their concurrent interactions can be deadly.

In order for the bug described in this post to occur we need a complex
interplay of features, though not, curiously enough, any
concurrency. This post will have to cover Deletes, Read Repair, AAE,
and Hand off in Riak as all these processes have a part to play.

As the quote above suggests, it is important to point out that the
client is not the only thing that initiates the movement of data in
Riak. As a database system Riak has processes and protocols that act
on data to ensure Riak is able to keep its promises around consistency
and availability. This post will cover those systems to a depth
necessary to understand the bug.

This blog post will introduce each of the subsystems/processes in Riak
that have a part to play in the bug, and then show how their interplay
can be "deadly." Finally we'll show a simple setting that mitigates
against the most common form of the bug, before considering what will
come in the next part of the series.

## 0. Why RYOW, again?

The bug itself is very similar to the requirement to Read Your Own
Writes for Client Version Vectors, so if you haven't read
[part one](http://basho.com/posts/technical/vector-clocks-revisited/)
now is a good time to do so.

As a reminder: an actor in a version vector must increment its own
counter each time it updates a value. If an actor can not read its own
last update in the version vector, it cannot issue a new event that is
certain to be greater than the last. The first post in this series
showed how this can lead to data loss. How can it be that some vnode
as the actor could fail to read its own last write, isn't a vnode
where the database stores data? The simplest answer is, deletes.

## 1. Deletes are hard

Deletes are hard in an eventually consistent distributed system. Riak
allows concurrent writes to the same value, and it also allows a value
to be concurrently deleted and updated. Which operation "wins", the
update or the delete? As with concurrent updates to a key, version
vectors arbitrate. You can read more about
[deletes in the Riak documentation](http://docs.basho.com/riak/latest/ops/advanced/deletion),
but this post will cover all that is needed to understand the bug.

### 1.1. Tombstones

Rather than physically deleting a key, we can logically delete it. We
read the key and get its version vector, and write a special
_tombstone_ value back to Riak with the version vector as a context. A
delete then behaves like any other write. If the key was concurrently
updated, the version vector detects this, and the tombstone and
concurrent value become siblings. If there is no concurrent update
only the tombstone is recorded on disk. A request to read a key that
only has a tombstone value will return `not_found`. Riak understands
tombstones to mean logical deletion. A
[client](http://docs.basho.com/riak/latest/ops/advanced/deletion/#Client-Library-Examples)
can also ask Riak for the "deleted vclock" on a get, to ensure that a
new write descends a tombstone.

### 1.2. Reaping: I want my disk space back!

Disks are cheap and disks are big, but they're neither free nor
infinitely large, and customers would like to see the deletion of
values reflected in increased disk space (I know! Crazy!) Even if a
tombstone is just a version vector and a small special value actual
removal of the key data is a requirement. The process by which Riak
reclaims space is called tombstone reaping. It is reasonably complex:

1. Client issues `delete` command
2. Riak writes special `tombstone` with Version Vector
3. Riak internally performs a `GET` on the key, with the [quorum](http://docs.basho.com/riak/latest/theory/concepts/glossary/#Quorum) value set to `all` (which means "ask all the replicas for the value, please.")
4. If the result of the `GET` is a tombstone AND all vnodes that reply are [primaries](http://docs.basho.com/riak/latest/theory/concepts/glossary/#Sloppy-Quorum) the
    vnodes are told they may physically remove the key
5. The vnode will read the key, check it is still tombstone, check the `delete_mode`
   and finally delete the tombstone.

Step 4 above amounts to Riak declaring unanimously that all primary
replicas agree on a tombstone value before issuing the final delete
that reaps the tombstone.

What is `delete_mode` as mentioned in step 5? It is a setting which can be one of

* `keep` - never delete the tombstone
* `immediate` - remove the tombstone at once
* `integer` - remove the tombstone after some time, for example `3000`
  means remove after 3 seconds

Read
[the documentation](http://docs.basho.com/riak/latest/ops/advanced/deletion/#Configuring-Object-Deletion)
for more details but I'll cover these settings as they pertain to the
bug later.

Clearly deletes are hard. The summary though is that Riak needs to see
all primary replicas agreeing on a logical delete before a physical
delete is considered.

## 2. Anti-Entropy

 Eventual Consistency is informally defined by Werner Vogels as

> The storage system guarantees that if no new updates are made to the
> object eventually all accesses will return the last updated value.

It is better if "eventually" is sooner rather than later, so Riak
works hard to ensure that all replicas agree as soon as
possible. There are three main processes for this: Read Repair, Active
Anti-Entropy, and Hand Off.

### 2.1 Read Repair

[Read repair](http://docs.basho.com/riak/latest/theory/concepts/Replication/#Read-Repair)
is an opportunistic or passive anti-entropy mechanism that Riak
employs to ensure that all replicas of a value agree. As the name
suggests, read Repair occurs when a client reads data from Riak.

When performaing a read request Riak asks every replica for the
value. Each replica responds with its local copy. Using the Version
Vector Riak can detect if some replica is behind, or in conflict, and
send the most up-to-date value to that replica to be stored,
"repairing" that replica. It is a curious fact that _all_ the replying
vnodes may require read repair as the "most up-to-date value" could be
the result of _merging_ all the responses. Imagine, for example, 3
clients each writing a different value, concurrently, to 3 vnodes. Or
a 3 way network partition with vnodes `A`, `B`, and `C` each being in
a different partition

### 2.2 AAE

[Active Anti-Entropy](http://docs.basho.com/riak/latest/theory/concepts/aae/),
or AAE does not depend on a client reading a value. As the name
suggests it is a process that runs in the background, actively
attempting to ensure all replicas agree on the current value for a
key. Without going into any details of _how_, AAE detects differences
between values and resolves the differences by asking Riak to perform
a `GET` operation internally, thus triggering read repair. AAE is not
strictly necessary for the instance of the bug we are discussing. In
the example AAE and Read Repair are interchangeable.

### 2.3 Hand Off

[Hand Off](http://docs.basho.com/riak/latest/theory/concepts/glossary/#Hinted-Handoff)
is a process that moves data after some failure or
[network partition](https://queue.acm.org/detail.cfm?id=2655736).

If key `X` should be stored on node `A` and node `A` is unavailable
when a client wishes to write, then some other node `A'` will perform
that write as a _fallback_. When node `A` is available again then the
fallback node will _hand off_ any data it stored. All this means is
node `A'` sends any data that it stored for node `A` back to node
`A`. Of course the magic of Version Vectors is how node `A` knows if
it should add node `A'`s data as a sibling, discard it, or overwrite
its local data.

## 3. Doomstones

Finally we have all the knowledge we need to understand the issue.

The example I'm going to use has deletes, read repair, and hand
off. It's a reasonably complex example, but one that has been seen in
the wild.

### 3.1. The Delete

A client decides to delete key `X`. It reads key `X` and gets the
Version Vector

    [{A, 2}]

Which means that vnode `A` has handled two updates to `X`. The Client
sends the delete command and version vector to Riak.

### 3.2. The Tombstone

Riak creates a `tombstone` value and writes it. However, only primary
nodes `A` and `B` are available, node `C` appears offline, maybe some
congestion at a network switch. Maybe an operator took `C` offline to
replace a faulty NIC. Whatever, node `C'` handles the write of the
tombstone as a _fallback_. The client is notified the delete succeeded,
and its part is done.

### 3.3. The Read Repair

Our cluster is in this state: the `tombstone` is on `A`, `B`, and
`C'`. As described in the section on deletes, Riak now performs a
`GET` operation to see if all primaries unanimously agree on the
tombstone value. By now `C` is back online and returns
`not_found`. It's OK, _Read Repair_ kicks in, and sends the tombstone
to `C`. Or instead maybe AAE causes the tombstone to find its way to
`C`.

### 3.4. The Reap

Now our cluster has the tombstone on `A`, `B`, `C` and `C'`. A read to
key `X` occurs. The client receives a `not_found`, and since all nodes
have the tombstone, and all are primaries, the _reap_ logic is run.

Nodes `A`, `B`, and `C` remove the tombstone. `C'` is not involved in
the read, and is not told to reap.

### 3.5. A New Write: History Repeats

A client writes a new value for `X`. Node `A` coordinates. The new
value is assigned the Version Vector:

    [{A, 1}]

Vnode `A` replicates to `B` and `C`. Our cluster is in this state:

    A, B, C = [{A, 1}] NewValue
    C'      = [{A, 2}] Tombstone

### 3.6. The Doomstone Strikes

This would be fine, except lingering on that fallback node `C'` is a
tombstone with the version vector

    [{A, 2}]

Handoff runs. `C'` sends its value to `C`. Node `C` looks at its local
Version Vector for key `X`, sees that the incoming handed off Version
Vector dominates it, and writes the tombstone.

    [{A, 1}] < [{A, 2}]

Later, AAE or read repair will spread the tombstone to nodes `A` and
`B`, removing the value for `[{A, 1}]` on those replicas, too.

### 3.7. What Just Happened?

The tombstone _looks_ like it is from a later causal time, but it's
actually from an earlier temporal time. The tombstone is from the
_first_ time node `A` acted on key `X`. The new value of key `X`, has
the Version Vector `[{A, 1}]` but from the _second_ time node `A`
created and updated the value.

The tombstone has managed to silently delete the new value of key `X`,
 which is bad. The tombstone looks like it is from the future, or the
 new Version Vector for `X` looks like it is from the past.

This example is convoluted but the essence of the problem is much like
the RYOW problem from part 1. If a vnode forgets the version vector
for a key (say by deleting the key) then it re-issues some event, in
this case `{A, 1}`.

### 3.8. Help?

Don't Panic! In this case the workaround is simple. Use `delete_mode =
keep`. With `delete_mode = keep` Riak will _NEVER_ reap the
tombstone. Clients must use the `deleted_vlock` read
parameter. Recreating a key is then a new write, replacing the logical
tombstone with a new value. No data is lost, but the space
reclamation issue remains. If you are at all concerned, running Riak
prior to 2.1, and delete and recreate keys, then set `delete_mode =
keep` in your configuration.

## 4. Fault Tolerant?

This example is long and convoluted, thanks for staying with me. I
chose this example as it doesn't involve any extravagant failure,
solar flares, badly timed client interleavings, or other
improbabilities. This example just uses Riak behaving well and doing
what it should to preserve availability and consistency of data.

There are other ways for this issue to manifest. In the real world
disk errors occur. If your database is a replicated, fault tolerant
database, and it gets an error from a disk, should it fail an
operation? When a Riak vnode can't read a local value for a key, it
treats the value as `not_found`, after all, there are `n` replicas of
the data, a write shouldn't fail if one is lost.

Turns out this can be bad, too. Failing to read the local version
vector for _whatever_ reason leads to a new version vector being
created for the key. Imagine some key `X` is on replicas `A`, `B`, and
`C` with version vector

    [{A, 3}, {B, 2}, {C, 5}]

For _whatever_ reason, a coordinating write on node `A` fails to read
`X`. Solar flare, disk error, operator removes the data directory
because "3 replicas, it's OK!", _anything_. At this point we assign
the Version Vector

    [{A, 1}]

to the new write. When it reaches replicas `B` and `C` they will
discard the new value as "already seen". Next Read Repair will cause
`A` to remove the value too. Same outcome (silent data loss), and from
a similar case: a vnode failing to read its own writes.

## 5. Summary

Don't worry: the main likely cause of this issue, Doomstones, can be
addressed with the simple configuration change to `delete_mode =
keep`. Doomstones are in no way unique to Riak: databases that use
temporal timestamps and Last Write Wins are far more susceptible.

To sum up: it is still a strict requirement that any actor in a
Version Vector must be able to Read its Own Writes, and if for any
reason an actor cannot, bad things happen. Deletes are just the
simplest and most likely reason that an actor is unable to read its
own writes.

This has already been a long post, almost 2500 words, and an attempt
to cover the solution now would be rushed. Instead, there is a fourth
part to this trilogy coming soon.


I gave a strong hint at the fix in section 3.7. In fact, it was hard
to write that paragraph without saying the key word _epoch_.

The next post describes per-key-actor-epochs in Version Vectors in
Riak 2.1.

------

With thanks to Basho Engineers Jon Meredith, Scott Fritchie, Zeeshan
Lahkani for review, and special thanks to Basho CSE Brian Sparrow for
his exhaustive documentation/walk through of Riak's delete code path.
